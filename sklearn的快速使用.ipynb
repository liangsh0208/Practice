{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import  datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "#from sklearn.datasets.samples_generator import  make_classification\n",
    "#X,y = make_classification(n_samples=6, n_features=5, n_informative=2, n_redundant=2, n_classes=2,\n",
    "#                         n_clusters_per_class=2, scale=1.0, random_state=20)\n",
    "#for x_, y_ in zip(X,y):\n",
    "#    print(y, end=\":\")\n",
    "#    print(x_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import  preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.23118282, -1.71131893,  1.71770304,  1.19857094, -0.51965501],\n",
       "       [ 0.39217125,  0.97024754, -1.00050853, -0.50892817,  1.77777141],\n",
       "       [ 1.03980354, -0.86828257,  0.75345647,  1.36421794, -1.03981919],\n",
       "       [-0.57862217,  0.08660018, -0.02668957, -0.4463902 , -0.4817237 ],\n",
       "       [-1.75732374,  0.437955  , -0.2542427 , -1.49369334, -0.64979461],\n",
       "       [ 1.13515394,  1.08479879, -1.18971871, -0.11377717,  0.91322111]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#数据归一化\n",
    "data = [[0, 0], [0, 0], [1, 1], [1, 1]]\n",
    "train_data = X\n",
    "scaler = preprocessing.StandardScaler().fit(train_data)\n",
    "scaler.transform(train_data)\n",
    "#scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40824829, -0.40824829,  0.81649658],\n",
       "       [ 1.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.70710678, -0.70710678]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#正则化\n",
    "X = [[ 1., -1.,  2.], [ 2.,  0.,  0.],[ 0.,  1., -1.]]\n",
    "X_normalized = preprocessing.normalize(X, norm='l2')\n",
    "X_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 1., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 1., 0., 1., 0., 0.],\n",
       "       [0., 1., 1., 0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot编码\n",
    "data = [[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]]\n",
    "encoder = preprocessing.OneHotEncoder().fit(data)\n",
    "encoder.transform(data).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 数据集拆分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import  train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.3, random_state=2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train)\n",
    "model.predict(X_test)\n",
    "\n",
    "model.get_params()\n",
    "model.score(data_X, data_y) #线性回归 R square; 分类问题: acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    fit_intercept：是否计算截距。False-模型没有截距\\n    normalize： 当fit_intercept设置为False时，该参数将被忽略。 如果为真，则回归前的回归系数X将通过减去平均值并除以l2-范数而归一化。\\n     n_jobs：指定线程数\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression(fit_intercept=True,normalize=False, copy_X=True, n_jobs=1)\n",
    "'''\n",
    "    fit_intercept：是否计算截距。False-模型没有截距\n",
    "    normalize： 当fit_intercept设置为False时，该参数将被忽略。 如果为真，则回归前的回归系数X将通过减去平均值并除以l2-范数而归一化。\n",
    "     n_jobs：指定线程数\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 4.2 逻辑回归LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import  LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0,fit_intercept=True,\n",
    "                           intercept_scaling=1, class_weight=None, random_state=None, \n",
    "                           solver='liblinear', max_iter=100, multi_class='ovr',verbose=0, \n",
    "                           warm_start=False, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'参数\\n---\\n    penalty：使用指定正则化项（默认：l2）\\n    dual: n_samples > n_features取False（默认）\\n    C：正则化强度的反，值越小正则化强度越大\\n    n_jobs: 指定线程数\\n    random_state：随机数生成器\\n    fit_intercept: 是否需要常量\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"参数\n",
    "---\n",
    "    penalty：使用指定正则化项（默认：l2）\n",
    "    dual: n_samples > n_features取False（默认）\n",
    "    C：正则化强度的反，值越小正则化强度越大\n",
    "    n_jobs: 指定线程数\n",
    "    random_state：随机数生成器\n",
    "    fit_intercept: 是否需要常量\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.35182749,  1.35898642, -2.0881359 , -0.97794004],\n",
       "       [ 0.72886793, -1.86086716,  0.61161749, -1.69920569],\n",
       "       [-1.57520998, -1.25719565,  2.05140514,  2.52676551]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 1, 2, 0, 2, 0, 2, 2, 1, 2, 2, 1, 0, 1, 2, 1, 0, 2, 0, 2,\n",
       "       0, 1, 0, 0, 1, 2, 0, 0, 2, 0, 0, 2, 2, 0, 0, 2, 0, 1, 0, 1, 0, 2,\n",
       "       2])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 1, 2, 0, 2, 0, 1, 2, 2, 2, 2, 1, 0, 1, 2, 1, 0, 2, 0, 2,\n",
       "       0, 1, 0, 0, 1, 2, 0, 0, 2, 0, 0, 2, 2, 0, 0, 2, 0, 1, 0, 1, 0, 2,\n",
       "       1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3 朴素贝叶斯算法NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n文本分类问题常用MultinomialNB\\n参数\\n---\\n    alpha：平滑参数\\n    fit_prior：是否要学习类的先验概率；false-使用统一的先验概率\\n    class_prior: 是否指定类的先验概率；若指定则不能根据参数调整\\n    binarize: 二值化的阈值，若为None，则假设输入由二进制向量组成\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = naive_bayes.GaussianNB()\n",
    "model = naive_bayes.MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None)\n",
    "model = naive_bayes.BernoulliNB(alpha=1.0, binarize=0.0, fit_prior=True, class_prior=None)\n",
    "\"\"\"\n",
    "文本分类问题常用MultinomialNB\n",
    "参数\n",
    "---\n",
    "    alpha：平滑参数\n",
    "    fit_prior：是否要学习类的先验概率；false-使用统一的先验概率\n",
    "    class_prior: 是否指定类的先验概率；若指定则不能根据参数调整\n",
    "    binarize: 二值化的阈值，若为None，则假设输入由二进制向量组成\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2222222222222222"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4 决策树DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tree.DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, \n",
    "                                    min_samples_leaf=1, min_weight_fraction_leaf=0.0,\n",
    "                                    max_features=None, random_state=None, max_leaf_nodes=None, \n",
    "                                    min_impurity_decrease=0.0, min_impurity_split=None,class_weight=None, \n",
    "                                    presort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'参数\\n---\\n    criterion ：特征选择准则gini/entropy\\n    max_depth：树的最大深度，None-尽量下分\\n    min_samples_split：分裂内部节点，所需要的最小样本树\\n    min_samples_leaf：叶子节点所需要的最小样本数\\n    max_features: 寻找最优分割点时的最大特征数\\n    max_leaf_nodes：优先增长到最大叶子节点数\\n    min_impurity_decrease：如果这种分离导致杂质的减少大于或等于这个值，则节点将被拆分。\\n'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"参数\n",
    "---\n",
    "    criterion ：特征选择准则gini/entropy\n",
    "    max_depth：树的最大深度，None-尽量下分\n",
    "    min_samples_split：分裂内部节点，所需要的最小样本树\n",
    "    min_samples_leaf：叶子节点所需要的最小样本数\n",
    "    max_features: 寻找最优分割点时的最大特征数\n",
    "    max_leaf_nodes：优先增长到最大叶子节点数\n",
    "    min_impurity_decrease：如果这种分离导致杂质的减少大于或等于这个值，则节点将被拆分。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.5 支持向量机SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import  SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(C=1.0, kernel='rbf', gamma='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'参数\\n---\\n    C：误差项的惩罚参数C\\n    gamma: 核相关系数。浮点数，If gamma is ‘auto’ then 1/n_features will be used instead.\\n'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"参数\n",
    "---\n",
    "    C：误差项的惩罚参数C\n",
    "    gamma: 核相关系数。浮点数，If gamma is ‘auto’ then 1/n_features will be used instead.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.6 k近邻算法KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = neighbors.KNeighborsClassifier(n_neighbors=5, n_jobs=1)\n",
    "model = neighbors.KNeighborsRegressor(n_neighbors=5, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'参数\\n---\\n    n_neighbors： 使用邻居的数目\\n    n_jobs：并行任务数\\n'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"参数\n",
    "---\n",
    "    n_neighbors： 使用邻居的数目\n",
    "    n_jobs：并行任务数\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.7 多层感知机（神经网络）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import  MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(hidden_layer_sizes=(50,),activation='relu', solver='adam', alpha=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'参数\\n---\\n    hidden_layer_sizes: 元祖\\n    activation：激活函数\\n    solver ：优化算法{‘lbfgs’, ‘sgd’, ‘adam’}\\n    alpha：L2惩罚(正则化项)参数。\\n'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"参数\n",
    "---\n",
    "    hidden_layer_sizes: 元祖\n",
    "    activation：激活函数\n",
    "    solver ：优化算法{‘lbfgs’, ‘sgd’, ‘adam’}\n",
    "    alpha：L2惩罚(正则化项)参数。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 模型评估与选择篇"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1 交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.10019732, 0.07443571, 0.07334208]),\n",
       " 'score_time': array([0.00074911, 0.00041175, 0.00039506]),\n",
       " 'test_score': array([1.        , 1.        , 0.91176471]),\n",
       " 'train_score': array([0.97058824, 0.95774648, 1.        ])}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(model,X=X_train,y=y_train, scoring=None, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"参数\\n---\\n    model：拟合数据的模型\\n    cv ： k-fold\\n    scoring: 打分参数-‘accuracy’、‘f1’、‘precision’、‘recall’ 、‘roc_auc’、'neg_log_loss'等等\\n\""
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"参数\n",
    "---\n",
    "    model：拟合数据的模型\n",
    "    cv ： k-fold\n",
    "    scoring: 打分参数-‘accuracy’、‘f1’、‘precision’、‘recall’ 、‘roc_auc’、'neg_log_loss'等等\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2 检验曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import  validation_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'参数\\n---\\n    model:用于fit和predict的对象\\n    X, y: 训练集的特征和标签\\n    param_name：将被改变的参数的名字\\n    param_range： 参数的改变范围\\n    cv：k-fold\\n   \\n返回值\\n---\\n   train_score: 训练集得分（array）\\n    test_score: 验证集得分（array）\\n'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_score, test_score = validation_curve(model, X,Y, param_name,param_range, cv=None, scoring=None, n_jobs=1)\n",
    "\n",
    "\"\"\"参数\n",
    "---\n",
    "    model:用于fit和predict的对象\n",
    "    X, y: 训练集的特征和标签\n",
    "    param_name：将被改变的参数的名字\n",
    "    param_range： 参数的改变范围\n",
    "    cv：k-fold\n",
    "   \n",
    "返回值\n",
    "---\n",
    "   train_score: 训练集得分（array）\n",
    "    test_score: 验证集得分（array）\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pickle',\"wb\") as f:\n",
    "    pickle.dump(model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 1, 2, 0, 2, 0, 2, 2, 1, 2, 2, 1, 0, 1, 2, 1, 0, 2, 0, 2,\n",
       "       0, 1, 0, 0, 1, 2, 0, 0, 2, 0, 0, 2, 2, 0, 0, 2, 0, 1, 0, 1, 0, 2,\n",
       "       1])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"model.pickle\",\"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn 自带方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import  joblib\n",
    "joblib.dump(model,'model_jb.pickle')\n",
    "model = joblib.load('model_jb.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
